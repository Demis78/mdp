% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/mdp-package.R
\docType{package}
\name{MDP}
\alias{MDP}
\alias{MDP-package}
\title{Markov Decision Processes (MDPs) in R}
\description{
Create and optimize MDPs or hierarchical MDPs with discrete time steps and state space.
}
\section{History}{

}

\section{To do}{


Dynamic hypergraph data type

Nested loading in memory (specify a HMDP with special actions containing child + father jump actions)

Change precision when reading trans pr integers from hgf file. Infact better to change the loading procedure!

getActionXX must be changed since is not precise enough (read numbers from a text string).

For function getPolicy add labels.actions = T and labels.states = T and getW = T

Specifiy how to calculate the discount factor (discrete or continious)

Split prob into 3 values when define the MDP

Update policy ite such that can start with a specified policy.

Index must start from 1 (R style).

MDPtoolbox style loading of model.

Possiblity to specify a model without a duration weight.

Value iteration under ave criterion
}
\author{
Lars Relund \email{lars@relund.dk}
}

